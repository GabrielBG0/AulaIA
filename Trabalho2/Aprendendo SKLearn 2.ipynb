{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "digits = datasets.load_digits()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import tree\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "\n",
    "dt = tree.DecisionTreeClassifier()\n",
    "knn = KNeighborsClassifier(n_neighbors=3)\n",
    "nb = GaussianNB()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import model_selection\n",
    "import numpy as np\n",
    "kf = model_selection.StratifiedKFold(n_splits=10)\n",
    "\n",
    "predicted_classes = dict()\n",
    "predicted_classes['tree'] = np.zeros(digits.target.shape[0])\n",
    "predicted_classes['knn'] = np.zeros(digits.target.shape[0])\n",
    "predicted_classes['naiveb'] = np.zeros(digits.target.shape[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for train, test in kf.split(digits.data, digits.target):\n",
    "    data_train, target_train = digits.data[train], digits.target[train]\n",
    "    data_test, target_test = digits.data[test], digits.target[test]\n",
    "\n",
    "    dt = dt.fit(data_train, target_train)\n",
    "    dt_predicted = dt.predict(data_test)\n",
    "    predicted_classes['tree'][test] = dt_predicted\n",
    "\n",
    "    knn = knn.fit(data_train, target_train)\n",
    "    knn_predicted = knn.predict(data_test)\n",
    "    predicted_classes['knn'][test] = knn_predicted\n",
    "\n",
    "    nb = nb.fit(data_train, target_train)\n",
    "    nb_predicted = nb.predict(data_test)\n",
    "    predicted_classes['naiveb'][test] = nb_predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "=======================================================================\nResultados do classificador: tree\n              precision    recall  f1-score   support\n\n           0       0.96      0.93      0.95       178\n           1       0.78      0.78      0.78       182\n           2       0.81      0.82      0.82       177\n           3       0.81      0.79      0.80       183\n           4       0.78      0.80      0.79       181\n           5       0.90      0.87      0.89       182\n           6       0.89      0.88      0.89       181\n           7       0.83      0.82      0.82       179\n           8       0.74      0.74      0.74       174\n           9       0.77      0.84      0.81       180\n\n    accuracy                           0.83      1797\n   macro avg       0.83      0.83      0.83      1797\nweighted avg       0.83      0.83      0.83      1797\n\n\nMatriz de confus達o: \n[[166   0   0   0   2   2   1   0   3   4]\n [  0 142  10   3   3   1   2   3   5  13]\n [  1   3 146   3   3   0   2   2  14   3]\n [  0   4   9 145   1   2   2   6   8   6]\n [  2  12   4   2 144   1   8   5   1   2]\n [  0   1   0   4   8 159   1   0   3   6]\n [  0   3   1   1  13   1 160   2   0   0]\n [  3   4   0   8   5   3   0 146   4   6]\n [  1  10   9   7   3   5   1   5 128   5]\n [  0   2   1   6   3   2   2   6   6 152]]\n\n\n\n=======================================================================\nResultados do classificador: knn\n              precision    recall  f1-score   support\n\n           0       0.99      1.00      1.00       178\n           1       0.93      0.99      0.96       182\n           2       0.99      0.97      0.98       177\n           3       0.96      0.96      0.96       183\n           4       0.99      0.98      0.99       181\n           5       0.98      0.98      0.98       182\n           6       0.98      0.99      0.99       181\n           7       0.99      0.99      0.99       179\n           8       0.97      0.95      0.96       174\n           9       0.97      0.95      0.96       180\n\n    accuracy                           0.98      1797\n   macro avg       0.98      0.98      0.98      1797\nweighted avg       0.98      0.98      0.98      1797\n\n\nMatriz de confus達o: \n[[178   0   0   0   0   0   0   0   0   0]\n [  0 180   0   0   0   1   1   0   0   0]\n [  0   4 171   1   0   0   0   0   1   0]\n [  0   0   1 176   0   1   0   2   2   1]\n [  0   1   0   0 178   0   1   0   0   1]\n [  0   0   0   0   0 178   1   0   0   3]\n [  1   1   0   0   0   0 179   0   0   0]\n [  0   0   0   0   0   0   0 178   0   1]\n [  0   6   0   2   0   0   0   0 166   0]\n [  0   1   0   4   1   1   0   0   2 171]]\n\n\n\n=======================================================================\nResultados do classificador: naiveb\n              precision    recall  f1-score   support\n\n           0       0.99      0.98      0.98       178\n           1       0.73      0.77      0.75       182\n           2       0.90      0.63      0.74       177\n           3       0.92      0.72      0.81       183\n           4       0.94      0.81      0.87       181\n           5       0.88      0.88      0.88       182\n           6       0.94      0.97      0.95       181\n           7       0.70      0.97      0.81       179\n           8       0.52      0.75      0.61       174\n           9       0.84      0.63      0.72       180\n\n    accuracy                           0.81      1797\n   macro avg       0.84      0.81      0.81      1797\nweighted avg       0.84      0.81      0.81      1797\n\n\nMatriz de confus達o: \n[[174   0   0   0   2   0   0   1   0   1]\n [  0 141   3   0   1   0   6   5  17   9]\n [  0  10 112   0   1   2   1   0  51   0]\n [  0   2   4 131   0   8   0   8  25   5]\n [  1   2   1   0 147   1   2  25   2   0]\n [  0   2   0   3   1 160   1   9   3   3]\n [  0   1   1   0   1   3 175   0   0   0]\n [  0   0   1   0   1   1   0 174   1   1]\n [  0  25   2   1   0   3   0  11 130   2]\n [  1  11   0   7   2   4   1  17  23 114]]\n\n\n\n"
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "for classifier in predicted_classes.keys():\n",
    "    print(\"=======================================================================\")\n",
    "    print(\"Resultados do classificador: %s\\n%s\\n\" \n",
    "    %(classifier, metrics.classification_report(digits.target, predicted_classes[classifier])))\n",
    "    print(\"Matriz de confus達o: \\n%s\\n\\n\\n\" %metrics.confusion_matrix(digits.target, predicted_classes[classifier]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}