{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import tree\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import model_selection\n",
    "from sklearn import metrics\n",
    "from sklearn import datasets\n",
    "import numpy as np\n",
    "\n",
    "dataset = datasets.load_digits()\n",
    "\n",
    "dt = tree.DecisionTreeClassifier()\n",
    "knn = KNeighborsClassifier()\n",
    "nb = GaussianNB()\n",
    "mlp = MLPClassifier()\n",
    "logReg = LogisticRegression()\n",
    "kf = model_selection.StratifiedKFold(n_splits=10)\n",
    "\n",
    "predicted_classes = dict()\n",
    "predicted_classes['tree'] = np.zeros(dataset.target.shape[0])\n",
    "predicted_classes['knn'] = np.zeros(dataset.target.shape[0])\n",
    "predicted_classes['naiveb'] = np.zeros(dataset.target.shape[0])\n",
    "predicted_classes['mlp'] = np.zeros(dataset.target.shape[0])\n",
    "predicted_classes['logReg'] = np.zeros(dataset.target.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "for train, test in kf.split(dataset.data, dataset.target):\n",
    "            data_train, target_train = dataset.data[train], dataset.target[train]\n",
    "            data_test, target_test = dataset.data[test], dataset.target[test]\n",
    "\n",
    "            dt = dt.fit(data_train, target_train)\n",
    "            dt_predicted = dt.predict(data_test)\n",
    "            predicted_classes['tree'][test] = dt_predicted\n",
    "\n",
    "            knn = knn.fit(data_train, target_train)\n",
    "            knn_predicted = knn.predict(data_test)\n",
    "            predicted_classes['knn'][test] = knn_predicted\n",
    "\n",
    "            nb = nb.fit(data_train, target_train)\n",
    "            nb_predicted = nb.predict(data_test)\n",
    "            predicted_classes['naiveb'][test] = nb_predicted\n",
    "\n",
    "            mlp = mlp.fit(data_train, target_train)\n",
    "            mlp_predicted = mlp.predict(data_test)\n",
    "            predicted_classes['mlp'][test] = mlp_predicted\n",
    "\n",
    "            logReg = logReg.fit(data_train, target_train)\n",
    "            logReg_predicted = logReg.predict(data_test)\n",
    "            predicted_classes['logReg'][test] = logReg_predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "=======================================================================\nResultados do classificador: tree\n              precision    recall  f1-score   support\n\n           0       0.95      0.93      0.94       178\n           1       0.75      0.76      0.75       182\n           2       0.80      0.80      0.80       177\n           3       0.80      0.79      0.80       183\n           4       0.84      0.80      0.82       181\n           5       0.87      0.86      0.87       182\n           6       0.87      0.87      0.87       181\n           7       0.82      0.82      0.82       179\n           8       0.71      0.72      0.71       174\n           9       0.76      0.82      0.79       180\n\n    accuracy                           0.82      1797\n   macro avg       0.82      0.82      0.82      1797\nweighted avg       0.82      0.82      0.82      1797\n\n\nMatriz de confusão: \n[[165   0   2   0   4   1   1   0   1   4]\n [  0 138  11   2   4   1   7   2   6  11]\n [  1   8 142   4   0   2   2   1  14   3]\n [  0   5   8 144   0   5   1   4  10   6]\n [  2  12   2   0 144   1  10   7   1   2]\n [  2   0   0   3   1 157   2   1   6  10]\n [  2   3   1   1  10   3 157   3   1   0]\n [  1   0   1  10   4   5   0 147   8   3]\n [  0  13   9   8   4   2   1   5 125   7]\n [  0   5   1   7   1   4   0  10   4 148]]\n\n\n\n=======================================================================\nResultados do classificador: knn\n              precision    recall  f1-score   support\n\n           0       1.00      1.00      1.00       178\n           1       0.91      0.99      0.95       182\n           2       0.99      0.96      0.97       177\n           3       0.97      0.96      0.96       183\n           4       0.99      0.98      0.99       181\n           5       0.98      0.97      0.98       182\n           6       0.99      0.99      0.99       181\n           7       0.96      0.98      0.97       179\n           8       0.96      0.93      0.94       174\n           9       0.95      0.94      0.95       180\n\n    accuracy                           0.97      1797\n   macro avg       0.97      0.97      0.97      1797\nweighted avg       0.97      0.97      0.97      1797\n\n\nMatriz de confusão: \n[[178   0   0   0   0   0   0   0   0   0]\n [  0 181   0   0   0   0   1   0   0   0]\n [  0   3 170   0   0   0   0   1   3   0]\n [  0   0   1 175   0   1   0   2   2   2]\n [  0   1   0   0 178   0   0   2   0   0]\n [  0   0   0   0   0 177   1   0   0   4]\n [  0   1   0   0   0   1 179   0   0   0]\n [  0   0   0   0   0   0   0 176   0   3]\n [  0  10   1   1   0   0   0   1 161   0]\n [  0   2   0   4   1   1   0   1   1 170]]\n\n\n\n=======================================================================\nResultados do classificador: naiveb\n              precision    recall  f1-score   support\n\n           0       0.99      0.98      0.98       178\n           1       0.73      0.77      0.75       182\n           2       0.90      0.63      0.74       177\n           3       0.92      0.72      0.81       183\n           4       0.94      0.81      0.87       181\n           5       0.88      0.88      0.88       182\n           6       0.94      0.97      0.95       181\n           7       0.70      0.97      0.81       179\n           8       0.52      0.75      0.61       174\n           9       0.84      0.63      0.72       180\n\n    accuracy                           0.81      1797\n   macro avg       0.84      0.81      0.81      1797\nweighted avg       0.84      0.81      0.81      1797\n\n\nMatriz de confusão: \n[[174   0   0   0   2   0   0   1   0   1]\n [  0 141   3   0   1   0   6   5  17   9]\n [  0  10 112   0   1   2   1   0  51   0]\n [  0   2   4 131   0   8   0   8  25   5]\n [  1   2   1   0 147   1   2  25   2   0]\n [  0   2   0   3   1 160   1   9   3   3]\n [  0   1   1   0   1   3 175   0   0   0]\n [  0   0   1   0   1   1   0 174   1   1]\n [  0  25   2   1   0   3   0  11 130   2]\n [  1  11   0   7   2   4   1  17  23 114]]\n\n\n\n=======================================================================\nResultados do classificador: mlp\n              precision    recall  f1-score   support\n\n           0       0.98      1.00      0.99       178\n           1       0.94      0.95      0.95       182\n           2       0.96      0.97      0.96       177\n           3       0.99      0.92      0.95       183\n           4       0.98      0.96      0.97       181\n           5       0.97      0.94      0.96       182\n           6       0.97      0.98      0.98       181\n           7       0.98      0.94      0.96       179\n           8       0.93      0.94      0.94       174\n           9       0.89      0.98      0.93       180\n\n    accuracy                           0.96      1797\n   macro avg       0.96      0.96      0.96      1797\nweighted avg       0.96      0.96      0.96      1797\n\n\nMatriz de confusão: \n[[178   0   0   0   0   0   0   0   0   0]\n [  0 173   1   0   0   1   2   0   1   4]\n [  0   3 172   0   0   0   0   0   1   1]\n [  0   0   5 168   0   2   0   2   4   2]\n [  2   0   0   0 174   0   1   1   2   1]\n [  0   1   0   1   0 171   2   0   0   7]\n [  2   0   0   0   0   0 177   0   2   0]\n [  0   0   0   0   2   0   0 169   1   7]\n [  0   5   2   1   1   1   0   0 164   0]\n [  0   2   0   0   0   1   0   0   1 176]]\n\n\n\n=======================================================================\nResultados do classificador: logReg\n              precision    recall  f1-score   support\n\n           0       0.97      0.99      0.98       178\n           1       0.89      0.90      0.89       182\n           2       0.96      0.95      0.96       177\n           3       0.95      0.91      0.93       183\n           4       0.95      0.93      0.94       181\n           5       0.92      0.93      0.92       182\n           6       0.94      0.97      0.95       181\n           7       0.97      0.91      0.94       179\n           8       0.92      0.87      0.89       174\n           9       0.84      0.92      0.88       180\n\n    accuracy                           0.93      1797\n   macro avg       0.93      0.93      0.93      1797\nweighted avg       0.93      0.93      0.93      1797\n\n\nMatriz de confusão: \n[[176   0   0   0   1   1   0   0   0   0]\n [  0 164   1   1   2   0   6   0   2   6]\n [  0   6 169   2   0   0   0   0   0   0]\n [  0   0   2 166   0   4   0   2   7   2]\n [  2   2   0   0 169   0   4   1   0   3]\n [  0   1   1   2   1 169   1   0   0   7]\n [  0   1   0   0   1   2 176   0   1   0]\n [  3   1   0   1   1   2   0 162   0   9]\n [  0  10   2   0   1   5   0   0 151   5]\n [  1   0   1   3   1   1   1   2   4 166]]\n\n\n\n"
    }
   ],
   "source": [
    "for classifier in predicted_classes.keys():\n",
    "            print(\n",
    "                \"=======================================================================\")\n",
    "            print(\"Resultados do classificador: %s\\n%s\\n\"\n",
    "                  % (classifier, metrics.classification_report(dataset.target, predicted_classes[classifier])))\n",
    "            print(\"Matriz de confusão: \\n%s\\n\\n\\n\" % metrics.confusion_matrix(\n",
    "                dataset.target, predicted_classes[classifier]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}